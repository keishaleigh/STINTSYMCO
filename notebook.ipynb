{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STINTSY Project - \n",
    "\n",
    "### Group 4 (S13)\n",
    "CAPAROS, MIGUEL ANTONIO <br> \n",
    "MARTINEZ, AZELIAH <br>\n",
    "PAREDES, BILL JETHRO <br>\n",
    "VILLANUEVA, KEISHA LEIGH <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction to the problem and dataset\n",
    "\n",
    "Select one real-world dataset from the list of datasets provided for the project. Each dataset is accompanied with a description file, which also contains detailed description of each feature.\n",
    "\n",
    "The target task (i.e., classification or regression) should be properly stated as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Labor Force Survey (LFS) is a nationwide quarterly survey conducted by the Philippine Statistics Authority (PSA). It aims to gather data on the demographic and socio-economic characteristics of the labor force, providing insights into employment, unemployment, and underemployment trends in the country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Description of the dataset\n",
    "\n",
    "• State a brief description of the dataset.\n",
    "\n",
    "• Provide a description of the collection process executed to build the dataset. Discuss the\n",
    "implications of the data collection method on the generated conclusions and insights. Note that you may need to look at relevant sources related to the dataset to acquire necessary information for this part of the project.\n",
    "\n",
    "• Describe the structure of the dataset file.\n",
    "- What does each row and column represent?\n",
    "- How many instances are there in the dataset?\n",
    "- How many features are there in the dataset?\n",
    "- If the dataset is composed of different files that you will combine in the succeeding\n",
    "steps, describe the structure and the contents of each file.\n",
    "\n",
    "• Discuss the features in each dataset file. What does each feature represent? All features, even those which are not used for the study, should be described to the reader. The purpose of each feature in the dataset should be clear to the reader of the notebook\n",
    "without having to go through an external link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "The Labor Force Survey (LFS) dataset contains information on individuals' demographic profiles, educational attainment, occupation types, work status, and income levels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection Process\n",
    "\n",
    "The PSA collects the LFS data through quarterly household surveys using face-to-face interviews. The survey employs a multi-stage sampling design to ensure that the sample accurately represents the population. The key steps in the data collection process include:\n",
    "\n",
    "1. Sampling frame creation: The PSA uses a master sample list derived from the 2015 Census of Population and Housing (CPH) as the sampling frame.\n",
    "2. Random selection of households: Households are randomly selected within each stratum (region or province) to create a representative sample.\n",
    "3. Face-to-face interviews: Field interviewers visit the sampled households and collect data through structured questionnaires.\n",
    "4. Data validation and processing: The collected data undergoes validation and consistency checks before being aggregated and published.\n",
    "\n",
    "The multi-stage sampling design of the Labor Force Survey (LFS) ensures representativeness across regions, but certain limitations exist. Non-response rates and inaccuracies in self-reported data may introduce bias, particularly in income-related features. Since the survey is conducted quarterly, it captures seasonal employment trends, which may affect the generalizability of insights over longer periods. Additionally, recall bias or misreporting could impact data reliability. Despite these limitations, the LFS remains a valuable source for policy-making and labor market analysis, providing key insights into the employment landscape of the Philippines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. List of requirements\n",
    "\n",
    "List all the Python libraries and modules that you used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "add here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation \n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt     # For creating plots and visualizations\n",
    "\n",
    "# Makes matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV.  Data preprocessing and cleaning\n",
    "\n",
    "Perform necessary steps before using the data. In this section of the notebook, please take note of the following:\n",
    "\n",
    "• If needed, perform preprocessing techniques to transform the data to the appropriate representation. This may include binning, log transformations, conversion to one-hot encoding, normalization, standardization, interpolation, truncation, and feature engineering, among others. There should be a correct and proper justification for the use of each preprocessing technique used in the project.\n",
    "\n",
    "• Make sure that the data is clean, especially features that are used in the project. This may include checking for misrepresentations, checking the data type, dealing with missing data, dealing with duplicate data, and dealing with outliers, among others. There should be a correct and proper justification for the application (or non-application) of each data cleaning method used in the project. Clean only the variables utilized in the study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset\n",
    "\n",
    "Our first step is to load the dataset using pandas, which will import the data into a pandas `DataFrame`. We use the [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "laborforce_df = pd.read_csv('Labor Force Survey 2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading a new dataset, it is advisable to utilize the [`info`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) function, as it displays general information regarding the dataset's structure and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 180862 entries, 0 to 180861\n",
      "Data columns (total 50 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   PUFREG           180862 non-null  int64  \n",
      " 1   PUFPRV           180862 non-null  int64  \n",
      " 2   PUFPRRCD         180862 non-null  int64  \n",
      " 3   PUFHHNUM         180862 non-null  int64  \n",
      " 4   PUFURB2K10       180862 non-null  int64  \n",
      " 5   PUFPWGTFIN       180862 non-null  float64\n",
      " 6   PUFSVYMO         180862 non-null  int64  \n",
      " 7   PUFSVYYR         180862 non-null  int64  \n",
      " 8   PUFPSU           180862 non-null  int64  \n",
      " 9   PUFRPL           180862 non-null  int64  \n",
      " 10  PUFHHSIZE        180862 non-null  int64  \n",
      " 11  PUFC01_LNO       180862 non-null  int64  \n",
      " 12  PUFC03_REL       180862 non-null  int64  \n",
      " 13  PUFC04_SEX       180862 non-null  int64  \n",
      " 14  PUFC05_AGE       180862 non-null  int64  \n",
      " 15  PUFC06_MSTAT     180862 non-null  object \n",
      " 16  PUFC07_GRADE     180862 non-null  object \n",
      " 17  PUFC08_CURSCH    180862 non-null  object \n",
      " 18  PUFC09_GRADTECH  180862 non-null  object \n",
      " 19  PUFC10_CONWR     180862 non-null  object \n",
      " 20  PUFC11_WORK      180862 non-null  object \n",
      " 21  PUFC12_JOB       180862 non-null  object \n",
      " 22  PUFC14_PROCC     180862 non-null  object \n",
      " 23  PUFC16_PKB       180862 non-null  object \n",
      " 24  PUFC17_NATEM     180862 non-null  object \n",
      " 25  PUFC18_PNWHRS    180862 non-null  object \n",
      " 26  PUFC19_PHOURS    180862 non-null  object \n",
      " 27  PUFC20_PWMORE    180862 non-null  object \n",
      " 28  PUFC21_PLADDW    180862 non-null  object \n",
      " 29  PUFC22_PFWRK     180862 non-null  object \n",
      " 30  PUFC23_PCLASS    180862 non-null  object \n",
      " 31  PUFC24_PBASIS    180862 non-null  object \n",
      " 32  PUFC25_PBASIC    180862 non-null  object \n",
      " 33  PUFC26_OJOB      180862 non-null  object \n",
      " 34  PUFC27_NJOBS     180862 non-null  object \n",
      " 35  PUFC28_THOURS    180862 non-null  object \n",
      " 36  PUFC29_WWM48H    180862 non-null  object \n",
      " 37  PUFC30_LOOKW     180862 non-null  object \n",
      " 38  PUFC31_FLWRK     180862 non-null  object \n",
      " 39  PUFC32_JOBSM     180862 non-null  object \n",
      " 40  PUFC33_WEEKS     180862 non-null  object \n",
      " 41  PUFC34_WYNOT     180862 non-null  object \n",
      " 42  PUFC35_LTLOOKW   180862 non-null  object \n",
      " 43  PUFC36_AVAIL     180862 non-null  object \n",
      " 44  PUFC37_WILLING   180862 non-null  object \n",
      " 45  PUFC38_PREVJOB   180862 non-null  object \n",
      " 46  PUFC40_POCC      180862 non-null  object \n",
      " 47  PUFC41_WQTR      180862 non-null  object \n",
      " 48  PUFC43_QKB       180862 non-null  object \n",
      " 49  PUFNEWEMPSTAT    180862 non-null  object \n",
      "dtypes: float64(1), int64(14), object(35)\n",
      "memory usage: 69.0+ MB\n"
     ]
    }
   ],
   "source": [
    "laborforce_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [`head`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) function to quickly view the first few rows of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUFREG</th>\n",
       "      <th>PUFPRV</th>\n",
       "      <th>PUFPRRCD</th>\n",
       "      <th>PUFHHNUM</th>\n",
       "      <th>PUFURB2K10</th>\n",
       "      <th>PUFPWGTFIN</th>\n",
       "      <th>PUFSVYMO</th>\n",
       "      <th>PUFSVYYR</th>\n",
       "      <th>PUFPSU</th>\n",
       "      <th>PUFRPL</th>\n",
       "      <th>...</th>\n",
       "      <th>PUFC33_WEEKS</th>\n",
       "      <th>PUFC34_WYNOT</th>\n",
       "      <th>PUFC35_LTLOOKW</th>\n",
       "      <th>PUFC36_AVAIL</th>\n",
       "      <th>PUFC37_WILLING</th>\n",
       "      <th>PUFC38_PREVJOB</th>\n",
       "      <th>PUFC40_POCC</th>\n",
       "      <th>PUFC41_WQTR</th>\n",
       "      <th>PUFC43_QKB</th>\n",
       "      <th>PUFNEWEMPSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2800</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>405.2219</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2800</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>388.8280</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2800</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>406.1194</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2800</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>405.2219</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2800</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>384.3556</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PUFREG  PUFPRV  PUFPRRCD  PUFHHNUM  PUFURB2K10  PUFPWGTFIN  PUFSVYMO  \\\n",
       "0       1      28      2800         1           2    405.2219         4   \n",
       "1       1      28      2800         1           2    388.8280         4   \n",
       "2       1      28      2800         1           2    406.1194         4   \n",
       "3       1      28      2800         2           2    405.2219         4   \n",
       "4       1      28      2800         2           2    384.3556         4   \n",
       "\n",
       "   PUFSVYYR  PUFPSU  PUFRPL  ...  PUFC33_WEEKS  PUFC34_WYNOT  PUFC35_LTLOOKW  \\\n",
       "0      2016     217       1  ...                                               \n",
       "1      2016     217       1  ...                                               \n",
       "2      2016     217       1  ...                                               \n",
       "3      2016     217       1  ...                                               \n",
       "4      2016     217       1  ...                                               \n",
       "\n",
       "   PUFC36_AVAIL  PUFC37_WILLING PUFC38_PREVJOB PUFC40_POCC PUFC41_WQTR  \\\n",
       "0                                                                    1   \n",
       "1                                                                    1   \n",
       "2                                                                    1   \n",
       "3                                                                    1   \n",
       "4                                                                    1   \n",
       "\n",
       "  PUFC43_QKB PUFNEWEMPSTAT  \n",
       "0         01             1  \n",
       "1         01             1  \n",
       "2         01             1  \n",
       "3         01             1  \n",
       "4         96             1  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laborforce_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "Detecting and managing missing values is crucial for data analysis. To identify missing data within our DataFrame, we will use the [`isnull`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html) function in combination with [`sum`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html). This approach allows us to understand the extent of missing values in each column, facilitating appropriate strategies for data cleaning and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data:\n",
      " PUFREG             0\n",
      "PUFPRV             0\n",
      "PUFPRRCD           0\n",
      "PUFHHNUM           0\n",
      "PUFURB2K10         0\n",
      "PUFPWGTFIN         0\n",
      "PUFSVYMO           0\n",
      "PUFSVYYR           0\n",
      "PUFPSU             0\n",
      "PUFRPL             0\n",
      "PUFHHSIZE          0\n",
      "PUFC01_LNO         0\n",
      "PUFC03_REL         0\n",
      "PUFC04_SEX         0\n",
      "PUFC05_AGE         0\n",
      "PUFC06_MSTAT       0\n",
      "PUFC07_GRADE       0\n",
      "PUFC08_CURSCH      0\n",
      "PUFC09_GRADTECH    0\n",
      "PUFC10_CONWR       0\n",
      "PUFC11_WORK        0\n",
      "PUFC12_JOB         0\n",
      "PUFC14_PROCC       0\n",
      "PUFC16_PKB         0\n",
      "PUFC17_NATEM       0\n",
      "PUFC18_PNWHRS      0\n",
      "PUFC19_PHOURS      0\n",
      "PUFC20_PWMORE      0\n",
      "PUFC21_PLADDW      0\n",
      "PUFC22_PFWRK       0\n",
      "PUFC23_PCLASS      0\n",
      "PUFC24_PBASIS      0\n",
      "PUFC25_PBASIC      0\n",
      "PUFC26_OJOB        0\n",
      "PUFC27_NJOBS       0\n",
      "PUFC28_THOURS      0\n",
      "PUFC29_WWM48H      0\n",
      "PUFC30_LOOKW       0\n",
      "PUFC31_FLWRK       0\n",
      "PUFC32_JOBSM       0\n",
      "PUFC33_WEEKS       0\n",
      "PUFC34_WYNOT       0\n",
      "PUFC35_LTLOOKW     0\n",
      "PUFC36_AVAIL       0\n",
      "PUFC37_WILLING     0\n",
      "PUFC38_PREVJOB     0\n",
      "PUFC40_POCC        0\n",
      "PUFC41_WQTR        0\n",
      "PUFC43_QKB         0\n",
      "PUFNEWEMPSTAT      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data = laborforce_df.isnull().sum()\n",
    "print(\"Missing data:\\n\", missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Exploratory data analysis\n",
    "\n",
    "Perform exploratory data analysis comprehensively to gain a good understanding of your dataset. In this section of the notebook, you must present relevant numerical summaries and visualizations. Make sure that each code is accompanied by a brief explanation. The whole process should be supported with verbose textual descriptions of your procedures and findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI.  Initial model training\n",
    "\n",
    "Use machine learning models to accomplish your chosen task (i.e., classification or regression) for the dataset. In this section of the notebook, please take note of the following:\n",
    "\n",
    "• The project should train and evaluate at least 3 different kinds of machine learning models. The models should not be multiple variations of the same model, e.g., three neural network models with different number of neurons.\n",
    "\n",
    "• Each model should be appropriate in accomplishing the chosen task for the dataset. There should be a clear and correct justification on the use of each machine learning model.\n",
    "\n",
    "• Make sure that the values of the hyperparameters of each model are mentioned. At the minimum, the optimizer, the learning rate, and the learning rate schedule should be discussed per model.\n",
    "\n",
    "• The report should show that the models are not overfitting nor underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII.  Error analysis\n",
    "\n",
    "Perform error analysis on the output of all models used in the project. In this section of the notebook, you should:\n",
    "\n",
    "• Report and properly interpret the initial performance of all models using appropriate evaluation metrics.\n",
    "\n",
    "• Identify difficult classes and/or instances. For classification tasks, these are classes and/or instances that are difficult to classify. Hint: You may use confusion matrix for this. For regression tasks, these are instances that produces high error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIII.  Improving model performance\n",
    "\n",
    "Perform grid search or random search to tune the hyperparameters of each model. You should also tune each model to reduce the error in difficult classes and/or instances. In this section of the notebook, please take note of the following:\n",
    "\n",
    "• Make sure to elaborately explain the method of hyperparameter tuning.\n",
    "\n",
    "• Explicitly mention the different hyperparameters and their range of values. Show the corresponding performance of each configuration.\n",
    "\n",
    "• Report the performance of all models using appropriate evaluation metrics and visualizations.\n",
    "\n",
    "• Properly interpret the result based on relevant evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IX. Model performance summary\n",
    "\n",
    "Present a summary of all model configurations. In this section of the notebook, do the following:\n",
    "\n",
    "• Discuss each algorithm and the best set of values for its hyperparameters. Identify the best model configuration and discuss its advantage over other configurations.\n",
    "\n",
    "• Discuss how tuning each model helped in reducing its error in difficult classes and/or instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X. Insights and conclusions\n",
    "\n",
    "Clearly state your insights and conclusions from training a model on the data. Why did some models produce better results? Summarize your conclusions to explain the performance of the models. Discuss recommendations to improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XI. References\n",
    "\n",
    "Cite relevant references that you used in your project. All references must be cited, including:\n",
    "\n",
    "• Scholarly Articles – Cite in APA format and put a description of how you used it for your work.\n",
    "\n",
    "• Online references, blogs, articles that helped you come up with your project – Put the website, blog, or article title, link, and how you incorporated it into your work.\n",
    "\n",
    "• Artificial Intelligence (AI) Tools – Put the model used (e.g., ChatGPT, Gemini), the complete transcript of your conversations with the model (including your prompts and its responses), and a description of how you used it for your work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
